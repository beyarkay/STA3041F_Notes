\section{3041F: Poisson Processes}
\subsection{3041F: Probability Integral Transform}
If we want a random variable, X, that should have a certain CDF, \(F_X()\),
we can take a uniform random variable \(U \sim U(0, 1)\) and 
pass it through the inverse of \(F_X()\) in order to get the random variable X:
\begin{equation*}
    F_X^{-1}(U) \text{ has CDF } F_X()
\end{equation*}


From this, the exponential distribution can be simulated as 
\begin{equation*}
    -\frac{1}{\lambda}ln(U) \sim Exp(\lambda)
\end{equation*}

And the Gamma distribution with \(n\) iid uniform random variables as:
\begin{equation*}
    -\frac{1}{\lambda}ln(U_1 \cdot U_2 \cdot \dots \cdot U_n) \sim Gamma(n, \lambda)
\end{equation*}

\subsection{3041F: Estimation}
See page 5 in the notes
\section{3041F: Basic Poisson Process}
\subsection{3041F: Poisson Postulates}
A counting process \(\{N(t), t \ge 0\}\) is a Poisson process with rate 
\( \lambda > 0 \), for small h, iff:
\begin{enumerate}
    \item N(0) = 0
    \item The process has independant and stationary increments
    \item \(\mathbb{P}[N(h) = 1] = \lambda h + o(h)\)

        So the Probability of one occurance within small timeframe h is equal to the rate parameter times h, plus some terms that go to zero.
    \item \(\mathbb{P}[N(h) > 1] = o(h)\)

        So the Probability of more than one occurance within small timeframe h goes to zero.
\end{enumerate}

\subsection{Poisson Process Information}
Proof page 7 in the notes.

The number of events in an interval of length t for a Poisson process with 
rate parameter \(\lambda\) is a random variable distributed \(Poi(\lambda t)\).

More explicitly, for n a non-negative integer:
\begin{equation*}
    \mathbb{P}[N(t) = n] = \frac{e^{-\lambda t}(\lambda t)^n}{n!}
\end{equation*}

The interarrival times \({T_n, n=1, 2, \dots}\) are iid \(\sim Exp(\lambda)\)

Define the sequence of waiting times \({S_n, n=1, 2, \dots}\) as: 
\begin{equation*}
    \left(S_n := \sum_{i=1}^n T_i\right) \sim Gamma(n, \lambda)
\end{equation*}


The sequence of arrival times \({S_i, i=1, 2, \dots, n}\) have the same distribution as an ordered sample of size \(n\) taken from \(U(0, S_n)\)


If we have a Poisson process \(\{N(t), t \ge 0\}\) where we classify each event as type 1
with probability \(p\) and type 2 with probability \(1-p\), then 
\(\{N_1(t), t \ge 0\}\) and \(\{N_2(t), t \ge 0\}\) are independant Poisson 
processes with parameters \(\lambda p\) and \(\lambda (1-p)\)


Let \(\{N^{(1)}(t), t \ge 0\}\) and \(\{N^{(2)}(t), t \ge 0\}\) be independant Poisson 
Processes with rates \(\lambda_1\) and \(\lambda_2\).
Also define the arrival times \(S^{(1)}_n\) and \(S^{(2)}_m\) as the arrival of the nth, mth event.

Then:
\begin{equation*}
    \mathbb{P}[S^{(1)}_n < S^{(2)}_m] = 
    \sum_{i=n}^{n + m - 1} 
    \binom{n + m - 1}{i} 
    \left( \frac{\lambda_1}{\lambda_1 + \lambda_2} \right)^i 
    \left( \frac{\lambda_2}{\lambda_1 + \lambda_2} \right)^{n + m - 1 - i}
\end{equation*}
\subsection{3041F: Modelling Poisson Processes}
There are two forms for modelling a Poisson process. 
Either you decide on how many events you want and let the events dictate the timeframe,
or you decide on the timeframe you want and take note of the events in that timeframe.

\paragraph{Generating n events} Calculate the events by sampling from a uniform distribution and then calculating \(T_i = -\frac{1}{\lambda} ln(U_i(0,  1))\) for \(i = 1, \dots, n\). 
\paragraph{Generating events in timeframe} Define the interarrival times as \(T_1, \dots, 
T_N\) where all interarrival times are in the interval \([0, T]\)
\subsection{3041F: Estimation of Poisson Processes}
Again, there are two scenarios. Either generate n events, or generate events within a timeframe \([0, t]\).

If the first n events of a process are observed as the interarrival times \(t_i, \dots, t_n\). Then the MLE of \(\lambda\) is:
\begin{equation*}
    \hat{\lambda}_{MLE} = \frac{n}{\sum_{i=1}^{n}t_i}
\end{equation*}


Alternatively, if there are N observed events in a given time interval \([0, T]\), then the MLE doesn't depend on the observed interarrival times and is:
\begin{equation*}
    \hat{\lambda}_{MLE} = \frac{N}{T}
\end{equation*}
Also, since \(N \sim Poi(\lambda T)\), \(\hat{\lambda}_{MLE}\) is an unbiased estimate of 
\(\lambda\) with variance \(\frac{\lambda}{T}\).
\section{3041F: Compound Poisson Processes}
For regular poisson processes, every event is identical and increases the count
by a certain amount. The events themselves aren't random, it's only the
duration inbetween events which is random.

For Compound Poisson Processes, both the duration between events, and the
amount by which our count will be changed is a random variable.

Let \(X_1, \dots X_N\) be a sequence of iid random variables with PFG
\( \mathbb{G}_X(s)\) and N a non-negative integer valued random variable with PGF
\( \mathbb{G}_N(s)\).

Then the count \(S_N\) and the PGF thereof are:
\begin{equation*}
    \begin{aligned}
        S_N &= \sum_{i=1}^{N} X_i \\
        \mathbb{G}_{S_N}(s) &= \mathbb{G}_N(\mathbb{G}_X(s)) \\
    \end{aligned}
\end{equation*}
The Expectation and Variance of \(S_N\) are given as a corollary:
\begin{equation*}
    \begin{aligned}
        \mathbb{E}[S_N] &= \mathbb{E}[N] \mathbb{E}[X]\\
        \mathbb{V}[S_N] &= \mathbb{E}[N]\mathbb{V}[X] + \left( \mathbb{E}[X]\right)^2 \mathbb{V}[N]\\
    \end{aligned}
\end{equation*}
Often the following result is useful, as we can go from a random sum of random
variables $S_n$ to just a simple counting process random variable $N(t)$:
\begin{equation*}
    \begin{aligned}
        \{S_n \le t\} &\iff \{N(t) \ge n\} \\
    \mathbb{P}[S_n \le t] &= \mathbb{P}[N(t) \ge n]  \\
    \end{aligned}
\end{equation*}

We formally define a compound Poisson process as a stochastic 
process \(\{X(t), t > 0\}\) that can be represented as the sum of iid random variables \(X_i\) which are also independant of the Poisson process:
\begin{equation*}
    X(t) = \sum_{i = 1}^{N(t)} X_i
\end{equation*}

From this we can give the moments for a compound poisson process. With \(X(t)\) as the 
compound poisson process made up of the random variables \(X_i: i=1, 2, \dots\):
\begin{equation*}
    \begin{aligned}
        \mathbb{E}[X(t)] &= \lambda t \mathbb{E}[X]   \\
        \mathbb{V}[X(t)] &= \lambda t \mathbb{E}[X^2] \\
    \end{aligned}
\end{equation*}
\section{3041F: Non-homogeneous Poisson Processes}
Regular Poisson Processes don't care what time it is. 
The rate parameter \(\lambda\) is constant, it doesn't change. This means that the frequency of events is constant.
Non-homogeneous Poisson processes replace the constant rate parameter \(\lambda\) with a function that depends on the time, called the intensity function \(\lambda(t)\).

The non-homogeneous poisson postulates have to be rephrased slightly:

A counting process \(\{N(t), t \ge 0\}\) is a Poisson process with intensity function
\( \lambda(t) > 0 \) and \(t > 0 \) for small h, iff:
\begin{enumerate}
    \item N(0) = 0
    \item The process has independant increments (we drop the requirement for stationary increments)
    \item \(\mathbb{P}[N(t + h) - N(t) = 1] = \lambda(t) h + o(h)\)

        So the Probability of one occurance within small timeframe t to t + h is equal to the intensity( at time t) multiplied by h, plus some terms that go to zero.
    \item \(\mathbb{P}[N(t + h) - N(t) > 1] = o(h)\)

        So the Probability of more than one occurrence within small timeframe from t to t + h goes to zero.
\end{enumerate}
\subsection{3041F: Mean Value Function}
Define the mean value function m(t) the integral from 0 to t of \(\lambda(t)\):
\begin{equation*}
    m(t) = \int_{0}^{t} \lambda(u) \, du
\end{equation*}
And then the number of events in a time interval (t, t + s] for a
non-homogeneous Poisson process is $\sim Poi({\color{BrickRed}{m(t + s) -
m(t)}})$, with colours added to make it clear that ${\color{BrickRed}{m(t +
s) - m(t)}}$ is just the rate parameter to a Poisson distribution.


In English, the number of events over a given interval is poisson 
distributed with a rate proportional to the total intensity over that interval. So the probability looks like:
\begin{equation*}
    \begin{aligned}
        \mathbb{P}[N(t + s) - N(t) = n] &= \frac{
            e^{-\left({\color{BrickRed}{m(t+s) - m(t)}}\right)} 
            \cdot \left( {\color{BrickRed}{m(t+s) - m(t)}}\right)^n
        }{n!} \\
        \mathbb{P}[N(t) \ge n] &= \sum_{j=n}^{\infty} \frac{ m(t)^j e^{-m(t)}
        }{ j!  } \\
        \end{aligned}
    \end{equation*}
\subsection{3041F: Simulation of a non-homogeneous Poisson Process}
Suppose that events arrive according to a poisson process with rate
\(\lambda\), but we only consider some of the events, choosing events with
probability p(t).\newline \newline

This describes a non-homogeneous Poisson process with intensity function
\(\lambda(t) = \lambda \cdot p(t)\).  We can therefore simulate a
non-homogeneous Poisson process by first using our methods for homogeneous
poisson processes, and then discarding events according to the probability
function p(t).  \newline \newline

\subsubsection{The Thinning algorithm}
The thinning algorithm generates a non-homogeneous poisson process by finding an constant valued 
approximation of the rate function, generating a homogeneous poisson process according to this 
constant, and then discarding some events such that the approximation of the rate function 
becomes the actual rate function.

If we want to simulate over a time interval [0, T] according to intensity function 
\(\lambda(t) > 0\) first generate events according to a poisson process with rate \(\lambda\)
over the interval [0, T] to give the N interarrival times \(T_1, \dots, T_N\).\newline
Then select \(\lambda_{max}\) such that 
\begin{equation*}
    \lambda_{max} \ge \lambda(t) \qquad \forall \, t \in [0, T]
\end{equation*}

Finally, create an indicator function with \(\lambda_{max}\) to select only those events where
a Uniform random variable in the range [0, \(\lambda_{max}\)) is less than \(\lambda(t)\): 
\begin{equation*}
    U(0, \lambda_{max}) \le \lambda(t) \quad \text{for } t = \sum_{i=1}^{j} T_i
\end{equation*}

    Then all those selected events make up the required non-homogeneous poisson process.
    \subsubsection{Subintervals for simulations}
    The thinning algorithm will regect lots of events if the intensity function \(\lambda(t)\) 
    is very different from \(\lambda_{max}\). We can fix this by dividing up the time interval
    into multiple smaller subintervals, and then running the thinning algorithm individually on
    each of these sub-intervals. Each time calculating a new and different value for 
    \(\lambda_{max}\).
    \subsubsection{Combining homogeneous Poisson Processes}
    Since the sum of events for two independant Poisson Processes with rates 
    \(\lambda_1\) and \(\lambda_2\) is itself a Poisson Process with rate \(\lambda_1 + \lambda_2\)
    we can use this to efficiently create piecewise Poisson processes where the 
    intensity function \(\lambda(t)\) is sometimes constant.
    \subsection{3041F: Estimation of non-homogeneous Poisson Processess}
    The PDf of the ith interarrival time given the waiting time of the (i-1)th can be written as:

    \begin{equation*}
        f_{T_i | W_{i-1}}(t) = 
        \lambda(w_{i-1} + t) \cdot e^{-\left(m(w_{i-1} + t) - m(w_{i-w})\right)}
    \end{equation*}

    Note that the arrival times are independant due to the increments being independant. \newline \newline

    Note that the probability of the ith interarrival time being greater than some value t (given 
    the (i-1)th arrival time) is equivalent to the probability of there being zero events between 
    the (i-1)th arrival time and the (i-1)th arrival time plus t. This implies:

    \begin{equation*}
        \begin{aligned}
            \mathbb{P}[T_i > t | W_{i-1} = w_{i-1}] &= \mathbb{P}[N(w_{i-1} + t) - N(w_{i-1}) = 0] \\
                                                    &=  e^{-\left(m(w_{i-1} + t) - m(w_{i-w})\right)} \\
        \end{aligned}
    \end{equation*}
    \subsubsection{Likelihood for non-homogeneous Poisson Processes}
    In general, explicit expressions for the MLEs do not exist, and likelihood maximisation must be 
    done numerically.
    The notes give examples, but they all boil down to two different cases. The first case is when we have data about the first \(n\) arrivals, and can be calculated as so:
    \begin{enumerate}
        \item taking a given intensity function with unknown parameters \(\theta\) and observed waiting times \(w_1, \dots, w_n\),
        \item Calculating the log-likelihood function as 
            \begin{equation*}
                l(\theta) = \sum_{i=1}^{n}ln\left(\lambda(w_i; \theta)\right) - 
                \left(m(w_n; \theta) - m(w_0; \theta)\right)
            \end{equation*}
        \item and then maximising \(l\) with respect to \(\theta\) in order to find the MLEs for \(\theta\).
    \end{enumerate}

    The second case is where we've measured all arrivals in an interval [0, T], and can be 
    calculated as shown below. It is different, because we need to account for the probability that 
    we saw no additional events between our last observed event and T.
    \begin{enumerate}
        \item taking a given intensity function with unknown parameters \(\theta\) and observed waiting times \(w_1, \dots, w_n\). All waiting times should be within [0, T].
        \item Calculating the likelihood function as 
            \begin{equation*}
                L(\theta) = \prod_{i=1}^{N}\lambda(w_i; \theta) e^{-m(T; \theta)}
            \end{equation*}
        \item and then maximising \(L\) with respect to \(\theta\) will give the MLEs of \(\theta\).
    \end{enumerate}

    The notes also go into likelihood ratio tests for seeing if a particular Poisson process is non-
    homogeneous, but I'm not going to write that up here.
